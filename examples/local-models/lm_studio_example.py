#!/usr/bin/env python3
"""
Test ACE with LM Studio (Ollama-compatible model).

LM Studio runs an OpenAI-compatible API server, so we use the
openai/ prefix with a custom base_url instead of ollama/.
"""

from ace.integrations import ACELiteLLM
from ace import Sample, SimpleEnvironment
from pathlib import Path
import os


def main():
    print("ğŸ¤– Testing ACELiteLLM with LM Studio...")

    # LM Studio default endpoint
    lm_studio_url = "http://localhost:1234/v1"

    # 1. Create ACELiteLLM agent pointing to LM Studio
    # Note: Use "openai/" prefix with api_base for LM Studio
    print(f"\nğŸ“¡ Connecting to LM Studio at {lm_studio_url}...")

    # Set environment variable for LiteLLM to use custom endpoint
    os.environ["OPENAI_API_BASE"] = lm_studio_url

    skillbook_path = Path("lm_studio_learned_strategies.json")

    try:
        agent = ACELiteLLM(
            model="openai/local-model",  # LM Studio serves any model as 'local-model'
            max_tokens=512,
            temperature=0.2,
            is_learning=True,
            skillbook_path=str(skillbook_path) if skillbook_path.exists() else None,
        )
    except Exception as e:
        print(f"âŒ Failed to connect to LM Studio: {e}")
        print("\nğŸ’¡ Make sure:")
        print("1. LM Studio is running")
        print("2. A model is loaded")
        print("3. Server is enabled (default: http://localhost:1234)")
        return

    # 2. Test basic question
    print("\nâ“ Testing agent before learning:")
    test_question = "What is 2+2?"
    try:
        answer = agent.ask(test_question)
        print(f"Q: {test_question}")
        print(f"A: {answer}")
    except Exception as e:
        print(f"âŒ Failed to get answer: {e}")
        return

    # 3. Create training samples
    samples = [
        Sample(question="What is 2+2?", ground_truth="4"),
        Sample(question="What color is the sky?", ground_truth="blue"),
        Sample(question="Capital of France?", ground_truth="Paris"),
    ]

    # 4. Run learning
    print("\nğŸš€ Running ACE learning...")
    print("âš ï¸  Note: This may take a while with smaller local models")
    environment = SimpleEnvironment()

    try:
        results = agent.learn(samples, environment, epochs=1)
        successful_samples = len(
            [r for r in results if "Correct" in r.environment_result.feedback]
        )
        print(f"âœ… Successfully processed {successful_samples}/{len(results)} samples")
    except Exception as e:
        print(f"âŒ Learning failed: {e}")
        print("ğŸ’¡ Small models may struggle with structured JSON output")
        print("   Consider using Instructor wrapper for better reliability")
        results = []

    # 5. Check results
    print(f"\nğŸ“Š Trained on {len(results)} samples")
    print(f"ğŸ“š Skillbook now has {len(agent.skillbook.skills())} strategies")

    # 6. Test with learned knowledge
    print("\nğŸ§  Testing agent after learning:")
    for question in ["What is 3+3?", "What color is grass?"]:
        try:
            answer = agent.ask(question)
            print(f"Q: {question}")
            print(f"A: {answer}")
        except Exception as e:
            print(f"âŒ Error: {e}")

    # Show learned strategies
    if agent.skillbook.skills():
        print("\nğŸ’¡ Learned strategies:")
        for skill in agent.skillbook.skills()[:3]:
            helpful = skill.helpful
            harmful = skill.harmful
            score = f"(+{helpful}/-{harmful})"
            content = (
                skill.content[:70] + "..." if len(skill.content) > 70 else skill.content
            )
            print(f"  â€¢ {content} {score}")

    # 7. Save learned knowledge
    agent.save_skillbook(skillbook_path)
    print(f"\nğŸ’¾ Saved learned strategies to {skillbook_path}")


if __name__ == "__main__":
    main()
